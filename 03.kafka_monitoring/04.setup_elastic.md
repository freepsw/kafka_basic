# 접속할 서버의 위치 : Kafka Broker 서버 (kafka-demo 서버)
## [STEP 0] Prerequisite - Run apache kafka, producer, consumer
- 이전에 JMX를 활성화한 Apache Kafka를 실행한 상태라면, 
- "[STEP 0]" 단계는 생략하고 진행한다. 

### Java 설치 및 JAVA_HOME 설정
- kafka_basic/README.md에 명시된 가이드에 따라서
- java 설치 및 JAVA_HOME 설정
```
> sudo dnf install java-17-openjdk java-17-openjdk-devel
> java --version
openjdk version "17.0.6" 2023-01-17 LTS

# java home 경로 확인
> ls /usr/lib/jvm/jre-17-openjdk
bin  conf  include  legal  lib  release  tapset

# JAVA_HOME 설정
> echo 'export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which javac))))' | sudo tee -a /etc/profile
> source /etc/profile

> echo $JAVA_HOME
/usr/lib/jvm/java-17-openjdk-17.0.6.0.10-3.el9.x86_64

> ls $JAVA_HOME
bin  conf  include  legal  lib  release  tapset
```

### Kafka 실행
- Zookeeper 실행
- Kafka Server(Broker) 실행 
  - jMX Port 활성화
- kafka_basic > 03.kafka_monitoring > 01.setup_kafka.md 참고
```
# Start Zookeeper server
> cd ~/apps/kafka_2.12-3.6.2
> bin/zookeeper-server-start.sh config/zookeeper.properties

# Start Kafka Broker
> cd ~/apps/kafka_2.12-3.6.2
> vi config/server.properties
advertised.listeners=PLAINTEXT://kafka-demo:9092

# java.rmi.server.hostname은 본인의 VM 외부 IP로 변경
# rmi.server.hostname을 설정해야, 외부의 jconsole과 같은 도구에서 접속 가능
> export KAFKA_JMX_OPTS='-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false 
  -Dcom.sun.management.jmxremote.ssl=false 
  -Dcom.sun.management.jmxremote.port=9999 
  -Dcom.sun.management.jmxremote.rmi.port=9999 
  -Djava.rmi.server.hostname=34.47.111.223'

> env JMX_PORT=9999 bin/kafka-server-start.sh config/server.properties
```

# 접속할 서버의 위치 : Kafka Monitoring 서버 (kafka-monitoring 서버)
## [STEP 1] Install ELK Stack (Elasticsearch + Logstash + Kibana)
- Elasticsearch를 비즈니에서 활용시 주의사항 (OSS버전 vs Default)
    - OSS는 elasticsearch를 이용하여 별도의 제품/솔루션으로 판매할 목적인 경우에 활용
    - Basic은 기업 내부에서는 무료로 사용가능 
        - 즉 OSS 버전을 기반으로 elastic사에서 추가기능(ML, SIEM등)을 무료로 제공하는 것
    - 정리하면, OSS는 누구나 활용 가능한 오픈소스
        - 이를 이용해 별도의 제품을 만들어도 가능함.
        - elastic사도 OSS를 이용해서 basic 제품을 개발하고, 이를 무료로 제공함. 
        - 하지만, basic 버전의 소유권은 elastic사에 귀속됨(무로지만, 이를 이용해 비즈니스/사업을 하면 안됨)
    - http://kimjmin.net/2020/06/2020-06-elastic-devrel/
- Elastic stack 설치
  - - https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html 참고

### 0) Java 설치 및 JAVA_HOME 설정
- kafka_basic/README.md에 명시된 가이드에 따라서
- java 설치 및 JAVA_HOME 설정
```
> sudo dnf install -y java-17-openjdk java-17-openjdk-devel
> java --version
openjdk version "17.0.6" 2023-01-17 LTS

# JAVA_HOME 설정
> echo 'export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which javac))))' | sudo tee -a /etc/profile
> source /etc/profile

> echo $JAVA_HOME
/usr/lib/jvm/java-17-openjdk-17.0.6.0.10-3.el9.x86_64

> ls $JAVA_HOME
bin  conf  include  legal  lib  release  tapset
```

### 1) Install an Elasticsearch 
- config 설정 
    - 외부 접속 허용(network.host) : server와 client가 다른 ip가 있을 경우, 외부에서 접속할 수 있도록 설정을 추가해야함.
```
> mkdir ~/apps
> cd ~/apps

> sudo dnf install -y  wget
> wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.14.1-linux-x86_64.tar.gz
> tar -xzf elasticsearch-8.14.1-linux-x86_64.tar.gz
> cd ~/apps/elasticsearch-8.14.1
> vi config/elasticsearch.yml
# bind ip to connect from client  (lan이 여러개 있을 경우 외부에서 접속할 ip를 지정할 수 있음.)
# bind all ip server have "0.0.0.0"
network.host: 0.0.0.0   #(":" 다음에 스페이스를 추가해야 함.)

# kibana에서 보안정책 없이 접근 가능하도록 "false"로 변경
xpack.security.enabled: false
```

- 현재 상태로 실행하면 아래와 같은 오류 발생
```
> ./bin/elasticsearch
[2024-07-06T07:56:15,147][ERROR][o.e.b.Elasticsearch      ] [kafka-monitoring] node validation exception
[1] bootstrap checks failed. You must address the points described in the following [1] lines before starting Elasticsearch. For more information see [https://www.elastic.co/guide/en/elasticsearch/reference/8.14/bootstrap-checks.html]
bootstrap check failure [1] of [1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]; for more information see [https://www.elastic.co/guide/en/elasticsearch/reference/8.14/_maximum_map_count_check.html]
```

#### 오류 해결 : virtual memory error
- 시스템의 nmap count를 증가기켜야 한다.
- 에러 : [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
- https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
```
# 0) 현재 설정 값 확인
> cat /proc/sys/vm/max_map_count
65530

# 아래 3가지 방법 중 1가지를 선택하여 적용 가능
# 1-1) 현재 서버상태에서만 적용하는 방식
> sudo sysctl -w vm.max_map_count=262144

# 1-2) 영구적으로 적용 (서버 재부팅시 자동 적용)
> sudo vi /etc/sysctl.conf

# 아래 내용 추가
vm.max_map_count = 262144

# 1-3) 또는 아래 명령어 실행 
> echo vm.max_map_count=262144 | sudo tee -a /etc/sysctl.conf


# 3) 시스템에 적용하여 변경된 값을 확인
> sudo sysctl -p
vm.max_map_count = 262144
```


#### Run elasticsearch
```
> ./bin/elasticsearch
....................
[2024-07-02T12:41:39,687][INFO ][o.e.l.ClusterStateLicenseService] [instance-20240701-162846] license [2ce86f9d-ae5b-47c0-815a-35e4ad0d9ae2] mode [basic] - valid
[2024-07-02T12:41:46,485][INFO ][o.e.x.s.InitialNodeSecurityAutoConfiguration] [instance-20240701-162846] HTTPS has been configured with automatically generated certificates, and the CA's hex-encoded SHA-256 fingerprint is [6500b8c8df356e4965da2f1692d8569a4e3058f04522f945fd699b76d5c81c64]
[2024-07-02T12:41:46,489][INFO ][o.e.x.s.s.SecurityIndexManager] [instance-20240701-162846] security index does not exist, creating [.security-7] with alias [.security]
[2024-07-02T12:41:46,506][INFO ][o.e.x.s.e.InternalEnrollmentTokenGenerator] [instance-20240701-162846] Will not generate node enrollment token because node is only bound on localhost for transport and cannot connect to nodes from other hosts
[2024-07-02T12:41:46,559][INFO ][o.e.c.m.MetadataCreateIndexService] [instance-20240701-162846] [.security-7] creating index, cause [api], templates [], shards [1]/[0]
[2024-07-02T12:41:46,617][INFO ][o.e.x.s.s.SecurityIndexManager] [instance-20240701-162846] security index does not exist, creating [.security-7] with alias [.security]
[2024-07-02T12:41:46,839][INFO ][o.e.c.r.a.AllocationService] [instance-20240701-162846] current.health="GREEN" message="Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.security-7][0]]])." previous.health="YELLOW" reason="shards started [[.security-7][0]]"


✅ Elasticsearch security features have been automatically configured!
✅ Authentication is enabled and cluster connections are encrypted.

ℹ️  Password for the elastic user (reset with `bin/elasticsearch-reset-password -u elastic`):
  y3_T1fGlqTC-SIzQ+6b+

ℹ️  HTTP CA certificate SHA-256 fingerprint:
  c63855add299fa4ad918216dee5dd2a53db9d678de942ac24b9ad505c110f2b8

ℹ️  Configure Kibana to use this cluster:
• Run Kibana and click the configuration link in the terminal when Kibana starts.
• Copy the following enrollment token and paste it into Kibana in your browser (valid for the next 30 minutes):
  eyJ2ZXIiOiI4LjE0LjAiLCJhZHIiOlsiMTAuMTc4LjAuNjo5MjAwIl0sImZnciI6ImM2Mzg1NWFkZDI5OWZhNGFkOTE4MjE2ZGVlNWRkMmE1M2RiOWQ2NzhkZTk0MmFjMjRiOWFkNTA1YzExMGYyYjgiLCJrZXkiOiJoOW9NaDVBQmc2cDVsVjZBZmthUDpOX3gzbDJ4ZlFmeUNqRWludllLRDR3In0=

ℹ️ Configure other nodes to join this cluster:
• Copy the following enrollment token and start new Elasticsearch nodes with `bin/elasticsearch --enrollment-token <token>` (valid for the next 30 minutes):
  eyJ2ZXIiOiI4LjE0LjAiLCJhZHIiOlsiMTAuMTc4LjAuNjo5MjAwIl0sImZnciI6ImM2Mzg1NWFkZDI5OWZhNGFkOTE4MjE2ZGVlNWRkMmE1M2RiOWQ2NzhkZTk0MmFjMjRiOWFkNTA1YzExMGYyYjgiLCJrZXkiOiJpZG9NaDVBQmc2cDVsVjZBZmthUjplYVplalpiOVNHT0NnalNRWFlhaVNBIn0=

```

#### Check elasticsearch is running
- Console을 이용한 접근
```
> export ELASTIC_PASSWORD="y3_T1fGlqTC-SIzQ+6b+"

> curl --cacert ~/apps/elasticsearch-8.14.1/config/certs/http_ca.crt -u elastic:$ELASTIC_PASSWORD https://localhost:9200 
{
  "name" : "instance-20240701-162846",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "BjsJfIIxSQySPV90paP3TQ",
  "version" : {
    "number" : "8.14.1",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "93a57a1a76f556d8aee6a90d1a95b06187501310",
    "build_date" : "2024-06-10T23:35:17.114581191Z",
    "build_snapshot" : false,
    "lucene_version" : "9.10.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}

## 아래와 같은 방법으로 접근도 가능함
> curl -k -v -u elastic https://34.64.103.143:9200
Enter host password for user 'elastic': ZG73I6D*OjUTT06oqZ4h
```
- Web Browser를 이용한 접근
  - Web brower 주소 창에서 "https://Elastic-server-ip:9200/" 입력
  - 팝업 창에서 user/password를 elastid/위에서 저장한 password 로 입력
  - web에서 elasticsearch 정보 확인



### 2) Install and run a kibana 
```
> cd ~/apps
> curl -O https://artifacts.elastic.co/downloads/kibana/kibana-8.14.1-linux-x86_64.tar.gz
> tar -xzf kibana-8.14.1-linux-x86_64.tar.gz
> cd ~/apps/kibana-8.14.1/
```

#### Kibana 설정 변경
- 외부 접속 가능하도록 설정 값 변경 
  - 외부의 어떤 IP에서도 접속 가능하도록 0.0.0.0으로 변경 (운영환경에서는 특정 ip대역만 지정하여 보안강화)
- elasticsearch 접속을 위한 user/password 설정
```
> vi config/kibana.yml  
# 외부에서 접근 가능하도록 설정 
server.host: "0.0.0.0"
```

#### Run kibana
```
> cd ~/apps/kibana-8.14.1/ 
> bin/kibana
.....
  log   [10:40:10.296] [info][server][Kibana][http] http server running at http://localhost:5601
  log   [10:40:12.690] [warning][plugins][reporting] Enabling the Chromium sandbox provides an additional layer of protection
```

#### (예외처리) Kibana 에러 시 기존 index 삭제 후 재시작
```
curl -XDELETE http://localhost:9200/.kibana
curl -XDELETE 'http://localhost:9200/.kibana*'
curl -XDELETE http://localhost:9200/.kibana_2
curl -XDELETE http://localhost:9200/.kibana_1
```


### 3) Install a logstash 
```
> cd ~/apps
> wget https://artifacts.elastic.co/downloads/logstash/logstash-8.14.1-linux-x86_64.tar.gz
> tar xvf logstash-8.14.1-linux-x86_64.tar.gz
> cd ~/apps/logstash-8.14.1
```

#### Test a logstash 
```
> bin/logstash -e 'input { stdin { } } output { stdout {} }'
# 실행까지 시간이 소요된다. (아래 메세지가 출력되면 정상 실행된 것으로 확인)
.........
[2024-07-02T15:42:37,938][INFO ][logstash.javapipeline    ][main] Pipeline started {"pipeline.id"=>"main"}
The stdin plugin is now waiting for input:
[2024-07-02T15:42:37,953][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}

mytest  <-- 메세지 입력 후 아래와 같이 출력되면 정상적으로 설치된 것
{
    "host" => {
        "hostname" => "instance-20240701-162846"
    },
    "event" => {
        "original" => "mytest"
    },
    "@version" => "1",
    "message" => "mytest",
    "@timestamp" => 2024-07-02T15:44:03.085998069Z
}
```

## [STEP 3] Collect JMX metric from apache kafka 
### 1) Logstach용 JMX 수집 metric 설정
```
## install jmx plugin
> cd ~/apps/logstash-8.14.1
> bin/logstash-plugin install logstash-input-jmx
> mkdir ~/jmx_conf
> vi ~/jmx_conf/broker01.conf

{
  "host" : "kafka-demo", 
  "port" : 9999,
  "alias" : "broker01",
  "queries" : [
  {
    "object_name" : "kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec",
    "attributes" : [ "OneMinuteRate" ],
    "object_alias" : "${type}.${name}"
  },
  {
    "object_name" : "kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec",
    "attributes" : [ "OneMinuteRate" ],
    "object_alias" : "${type}.${name}"
  },
  {
    "object_name" : "kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec",
    "attributes" : [ "OneMinuteRate" ],
    "object_alias" : "${type}.${name}"
  },
  {
    "object_name" : "kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions",
    "attributes" : [ "Value" ],
    "object_alias" : "${type}.${name}"
  },
  {
    "object_name" : "kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce",
    "attributes" : [ "Mean" ],
    "object_alias" : "${type}.${name}"
  },
  {
    "object_name" : "kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer",
    "attributes" : [ "Mean" ],
    "object_alias" : "${type}.${name}"
  }
 ]
}
```

### 2) Apache Kafka broker의 JMX에서 수집된 모니터링 metric을 Elasticsearch로 저장
- broker01.conf에 정의된 metric 들을 수집하여, 
- elasticsearch로 전송하는 logstash 설정
```
> mkdir ~/logstash_conf
> vi ~/logstash_conf/logstash_jmx.conf
# 아래 내용 입력 
input {
 jmx {
  path => "/home/freepsw18/jmx_conf"
  polling_frequency => 2
 }
}

output{
 stdout {
  codec => rubydebug
 }
 elasticsearch {
   hosts => "http://localhost:9200"
   index => "kafka_mon"
 }
}
```

- Logstash 실행
```
> cd ~/apps/logstash-8.14.1
> bin/logstash -f ~/logstash_conf/logstash_jmx.conf
```


### 생성된 index (kakfa-mon) 확인 
```
> curl -X GET "localhost:9200/_cat/indices/"
yellow open kafka_mon   U_6AA7ybS9Ss8_6WdLWfPQ 1 1 17 0 34.5kb 34.5kb 34.5kb

```

## [STEP 4] Kibana로 수집된 kafka metric 확인 및 시각화
### GCP 방화벽 허용 PORT 추가 
- Kibana 접속하기 위한 5601 PORT 허용

### Web Browser로 접속
- http://<kafka-monitoring vm IP>:5601
